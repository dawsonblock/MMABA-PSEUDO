{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "header"
            },
            "source": [
                "# üß† MMABA-PSEUDO: Mamba 2 Neural Memory Benchmark\n",
                "\n",
                "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/dawsonblock/MMABA-PSEUDO/blob/main/MMABA_Colab.ipynb)\n",
                "\n",
                "Train **Mamba 2 + PseudoMode Memory** on long-horizon RL tasks.\n",
                "\n",
                "| Task | Description | Difficulty |\n",
                "|:--|:--|:--|\n",
                "| `delayed_cue` | Remember signal for 200 steps | Medium |\n",
                "| `copy_memory` | Memorize and reproduce sequence | Hard |\n",
                "| `assoc_recall` | Learn key‚Üívalue pairs | Hard |\n",
                "| `tmaze` | Navigate using start hint | Very Hard |\n",
                "\n",
                "**Expected runtime**: ~1-2 hours on T4 GPU"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "setup_header"
            },
            "source": [
                "---\n",
                "## 1Ô∏è‚É£ Environment Setup"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "check_gpu"
            },
            "outputs": [],
            "source": [
                "#@title Check GPU Availability { display-mode: \"form\" }\n",
                "import torch\n",
                "\n",
                "if torch.cuda.is_available():\n",
                "    gpu_name = torch.cuda.get_device_name(0)\n",
                "    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
                "    print(f\"‚úÖ GPU Available: {gpu_name}\")\n",
                "    print(f\"   Memory: {gpu_memory:.1f} GB\")\n",
                "else:\n",
                "    print(\"‚ùå No GPU detected!\")\n",
                "    print(\"   Go to Runtime ‚Üí Change runtime type ‚Üí Select T4 GPU\")\n",
                "    raise RuntimeError(\"GPU required for efficient training\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "clone_repo"
            },
            "outputs": [],
            "source": [
                "#@title Clone Repository { display-mode: \"form\" }\n",
                "import os\n",
                "\n",
                "REPO_URL = \"https://github.com/dawsonblock/MMABA-PSEUDO.git\"\n",
                "REPO_NAME = \"MMABA-PSEUDO\"\n",
                "\n",
                "if os.path.exists(REPO_NAME):\n",
                "    print(f\"üìÅ Repository already exists, pulling latest...\")\n",
                "    %cd {REPO_NAME}\n",
                "    !git pull\n",
                "else:\n",
                "    print(f\"üì• Cloning {REPO_URL}...\")\n",
                "    !git clone {REPO_URL}\n",
                "    %cd {REPO_NAME}\n",
                "\n",
                "print(f\"\\n‚úÖ Working directory: {os.getcwd()}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "install_deps"
            },
            "outputs": [],
            "source": [
                "#@title Install Dependencies { display-mode: \"form\" }\n",
                "print(\"üì¶ Installing dependencies...\")\n",
                "!pip install -q torch numpy wandb einops triton\n",
                "\n",
                "print(\"\\nüì¶ Installing Mamba SSM...\")\n",
                "%cd mamba-main\n",
                "!pip install -q -e . 2>&1 | tail -5\n",
                "%cd ..\n",
                "\n",
                "# Verify installation\n",
                "import torch\n",
                "try:\n",
                "    from mamba_ssm.modules.mamba2 import Mamba2\n",
                "    print(\"\\n‚úÖ Mamba SSM installed successfully\")\n",
                "except ImportError as e:\n",
                "    print(f\"\\n‚ö†Ô∏è Mamba import warning: {e}\")\n",
                "    print(\"   Falling back to compatibility mode...\")\n",
                "\n",
                "print(f\"\\nüìä PyTorch: {torch.__version__}\")\n",
                "print(f\"   CUDA: {torch.version.cuda}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "config_header"
            },
            "source": [
                "---\n",
                "## 2Ô∏è‚É£ Configuration"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "config"
            },
            "outputs": [],
            "source": [
                "#@title Training Configuration { display-mode: \"form\" }\n",
                "\n",
                "#@markdown ### Task Settings\n",
                "TASK = \"delayed_cue\" #@param [\"delayed_cue\", \"copy_memory\", \"assoc_recall\", \"tmaze\"]\n",
                "CONTROLLER = \"mamba\" #@param [\"mamba\", \"gru\"]\n",
                "HORIZON = 200 #@param {type:\"integer\"}\n",
                "\n",
                "#@markdown ### Training Settings\n",
                "TOTAL_UPDATES = 2000 #@param {type:\"integer\"}\n",
                "NUM_ENVS = 64 #@param {type:\"integer\"}\n",
                "ROLLOUT_LENGTH = 256 #@param {type:\"integer\"}\n",
                "\n",
                "#@markdown ### PPO Hyperparameters\n",
                "LEARNING_RATE = 3e-4 #@param {type:\"number\"}\n",
                "ENT_COEF = 0.05 #@param {type:\"number\"}\n",
                "CLIP_COEF = 0.2 #@param {type:\"number\"}\n",
                "GAMMA = 0.99 #@param {type:\"number\"}\n",
                "\n",
                "#@markdown ### Model Architecture\n",
                "HIDDEN_SIZE = 128 #@param {type:\"integer\"}\n",
                "MEMORY_SLOTS = 16 #@param {type:\"integer\"}\n",
                "MEMORY_DIM = 64 #@param {type:\"integer\"}\n",
                "\n",
                "#@markdown ### Logging\n",
                "LOG_INTERVAL = 50 #@param {type:\"integer\"}\n",
                "USE_WANDB = False #@param {type:\"boolean\"}\n",
                "WANDB_PROJECT = \"neural-memory-suite\" #@param {type:\"string\"}\n",
                "RUN_NAME = \"mamba_colab\" #@param {type:\"string\"}\n",
                "\n",
                "# Build command\n",
                "CMD = f\"\"\"python3 neural_memory_long_ppo.py \\\\\n",
                "    --task {TASK} \\\\\n",
                "    --controller {CONTROLLER} \\\\\n",
                "    --device cuda \\\\\n",
                "    --horizon {HORIZON} \\\\\n",
                "    --num-envs {NUM_ENVS} \\\\\n",
                "    --rollout-length {ROLLOUT_LENGTH} \\\\\n",
                "    --total-updates {TOTAL_UPDATES} \\\\\n",
                "    --learning-rate {LEARNING_RATE} \\\\\n",
                "    --ent-coef {ENT_COEF} \\\\\n",
                "    --clip-coef {CLIP_COEF} \\\\\n",
                "    --gamma {GAMMA} \\\\\n",
                "    --hidden-size {HIDDEN_SIZE} \\\\\n",
                "    --memory-slots {MEMORY_SLOTS} \\\\\n",
                "    --memory-dim {MEMORY_DIM} \\\\\n",
                "    --log-interval {LOG_INTERVAL}\"\"\"\n",
                "\n",
                "if USE_WANDB:\n",
                "    CMD += f\" \\\\\n",
                "    --track \\\\\n",
                "    --wandb-project {WANDB_PROJECT} \\\\\n",
                "    --run-name {RUN_NAME}\"\n",
                "\n",
                "print(\"üìã Training Command:\")\n",
                "print(CMD)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "wandb_header"
            },
            "source": [
                "---\n",
                "## 3Ô∏è‚É£ WandB Login (Optional)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "wandb_login"
            },
            "outputs": [],
            "source": [
                "#@title Login to Weights & Biases { display-mode: \"form\" }\n",
                "#@markdown Run this cell if you enabled `USE_WANDB` above.\n",
                "\n",
                "if USE_WANDB:\n",
                "    import wandb\n",
                "    wandb.login()\n",
                "    print(\"‚úÖ WandB logged in!\")\n",
                "else:\n",
                "    print(\"‚ÑπÔ∏è WandB logging disabled. Set USE_WANDB=True to enable.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "train_header"
            },
            "source": [
                "---\n",
                "## 4Ô∏è‚É£ Run Training"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "run_training"
            },
            "outputs": [],
            "source": [
                "#@title Start Training { display-mode: \"form\" }\n",
                "print(f\"üöÄ Starting {CONTROLLER.upper()} training on {TASK}...\")\n",
                "print(f\"   Config: {NUM_ENVS} envs √ó {ROLLOUT_LENGTH} steps √ó {TOTAL_UPDATES} updates\")\n",
                "print(f\"   Total samples: {NUM_ENVS * ROLLOUT_LENGTH * TOTAL_UPDATES:,}\")\n",
                "print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
                "\n",
                "!{CMD}"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "benchmark_header"
            },
            "source": [
                "---\n",
                "## 5Ô∏è‚É£ Benchmark Suite (All Tasks)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "benchmark_suite"
            },
            "outputs": [],
            "source": [
                "#@title Run Full Benchmark Suite { display-mode: \"form\" }\n",
                "#@markdown This runs all 4 tasks sequentially (~4-6 hours total)\n",
                "\n",
                "RUN_BENCHMARK = False #@param {type:\"boolean\"}\n",
                "\n",
                "if RUN_BENCHMARK:\n",
                "    print(\"üèÉ Running full benchmark suite...\")\n",
                "    !python3 neural_memory_long_ppo.py \\\n",
                "        --benchmark-suite \\\n",
                "        --controller {CONTROLLER} \\\n",
                "        --device cuda \\\n",
                "        --num-envs 64 \\\n",
                "        --total-updates 2000 \\\n",
                "        --ent-coef 0.05\n",
                "else:\n",
                "    print(\"‚ÑπÔ∏è Benchmark suite disabled. Set RUN_BENCHMARK=True to run all tasks.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "compare_header"
            },
            "source": [
                "---\n",
                "## 6Ô∏è‚É£ Compare Controllers (Mamba vs GRU)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "compare_controllers"
            },
            "outputs": [],
            "source": [
                "#@title Run Controller Comparison { display-mode: \"form\" }\n",
                "#@markdown Train both Mamba and GRU on the same task for comparison\n",
                "\n",
                "RUN_COMPARISON = False #@param {type:\"boolean\"}\n",
                "COMPARISON_UPDATES = 500 #@param {type:\"integer\"}\n",
                "\n",
                "if RUN_COMPARISON:\n",
                "    print(\"üî¨ Running controller comparison...\")\n",
                "    \n",
                "    print(\"\\n\" + \"=\"*40)\n",
                "    print(\"Training MAMBA controller...\")\n",
                "    print(\"=\"*40)\n",
                "    !python3 neural_memory_long_ppo.py \\\n",
                "        --task {TASK} \\\n",
                "        --controller mamba \\\n",
                "        --device cuda \\\n",
                "        --num-envs 64 \\\n",
                "        --total-updates {COMPARISON_UPDATES} \\\n",
                "        --ent-coef 0.05 \\\n",
                "        --log-interval 50\n",
                "    \n",
                "    print(\"\\n\" + \"=\"*40)\n",
                "    print(\"Training GRU controller...\")\n",
                "    print(\"=\"*40)\n",
                "    !python3 neural_memory_long_ppo.py \\\n",
                "        --task {TASK} \\\n",
                "        --controller gru \\\n",
                "        --device cuda \\\n",
                "        --num-envs 64 \\\n",
                "        --total-updates {COMPARISON_UPDATES} \\\n",
                "        --ent-coef 0.05 \\\n",
                "        --log-interval 50\n",
                "    \n",
                "    print(\"\\n‚úÖ Comparison complete!\")\n",
                "else:\n",
                "    print(\"‚ÑπÔ∏è Comparison disabled. Set RUN_COMPARISON=True to compare Mamba vs GRU.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "analysis_header"
            },
            "source": [
                "---\n",
                "## 7Ô∏è‚É£ Quick Analysis"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "analysis"
            },
            "outputs": [],
            "source": [
                "#@title Analyze Results { display-mode: \"form\" }\n",
                "print(\"üìä Training completed!\")\n",
                "print(\"\\nKey metrics to look for:\")\n",
                "print(\"  - Return: Should trend toward 1.0 (perfect score)\")\n",
                "print(\"  - GateMean: Should be ~0.01-0.05 (sparse memory usage)\")\n",
                "print(\"  - KL: Should stay below 0.01 (stable training)\")\n",
                "print(\"\\nIf using WandB, view detailed charts at: https://wandb.ai\")"
            ]
        }
    ],
    "metadata": {
        "accelerator": "GPU",
        "colab": {
            "gpuType": "T4",
            "provenance": [],
            "toc_visible": true
        },
        "kernelspec": {
            "display_name": "Python 3",
            "name": "python3"
        },
        "language_info": {
            "name": "python"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 0
}