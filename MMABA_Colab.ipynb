{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# MMABA-PSEUDO: Mamba 2 Neural Memory Benchmark\n",
                "\n",
                "This notebook runs the Mamba 2 + PseudoMode Memory benchmark on Google Colab's free GPU.\n",
                "\n",
                "**Expected runtime**: ~1-2 hours on T4 GPU (vs ~13+ hours on MPS)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Setup Environment"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Check GPU availability\n",
                "!nvidia-smi"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Clone the repository\n",
                "!git clone https://github.com/dawsonblock/MMABA-PSEUDO.git\n",
                "%cd MMABA-PSEUDO"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Install dependencies\n",
                "!pip install -q torch numpy wandb einops"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Install Mamba (with CUDA support on Colab)\n",
                "%cd mamba-main\n",
                "!pip install -q -e .\n",
                "%cd .."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Verify CUDA availability\n",
                "import torch\n",
                "print(f\"PyTorch: {torch.__version__}\")\n",
                "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
                "if torch.cuda.is_available():\n",
                "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Run Training"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Train on Delayed Cue task with Mamba controller\n",
                "# Using CUDA with 64 parallel environments for fast training\n",
                "!python3 neural_memory_long_ppo.py \\\n",
                "    --task delayed_cue \\\n",
                "    --controller mamba \\\n",
                "    --device cuda \\\n",
                "    --num-envs 64 \\\n",
                "    --total-updates 2000 \\\n",
                "    --ent-coef 0.05 \\\n",
                "    --log-interval 50"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Alternative: Run with WandB Logging"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Uncomment and run this cell for WandB logging\n",
                "# import wandb\n",
                "# wandb.login()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Train with WandB tracking (uncomment to use)\n",
                "# !python3 neural_memory_long_ppo.py \\\n",
                "#     --task delayed_cue \\\n",
                "#     --controller mamba \\\n",
                "#     --device cuda \\\n",
                "#     --num-envs 64 \\\n",
                "#     --total-updates 2000 \\\n",
                "#     --ent-coef 0.05 \\\n",
                "#     --track \\\n",
                "#     --wandb-project neural-memory-suite \\\n",
                "#     --run-name mamba_delayedcue_colab"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Run Benchmark Suite (All Tasks)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Run all 4 tasks sequentially (takes ~4-6 hours)\n",
                "# !python3 neural_memory_long_ppo.py \\\n",
                "#     --benchmark-suite \\\n",
                "#     --controller mamba \\\n",
                "#     --device cuda \\\n",
                "#     --num-envs 64 \\\n",
                "#     --total-updates 2000"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Compare GRU vs Mamba"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Train with GRU controller for comparison\n",
                "# !python3 neural_memory_long_ppo.py \\\n",
                "#     --task delayed_cue \\\n",
                "#     --controller gru \\\n",
                "#     --device cuda \\\n",
                "#     --num-envs 64 \\\n",
                "#     --total-updates 2000"
            ]
        }
    ],
    "metadata": {
        "accelerator": "GPU",
        "colab": {
            "gpuType": "T4",
            "provenance": []
        },
        "kernelspec": {
            "display_name": "Python 3",
            "name": "python3"
        },
        "language_info": {
            "name": "python"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 0
}